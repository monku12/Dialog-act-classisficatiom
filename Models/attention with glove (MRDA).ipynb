{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3abaaec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "import gensim\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, load_model\n",
    "from keras import layers\n",
    "from keras.layers import Dense, LSTM, Embedding, Dropout, Bidirectional, Lambda, Flatten\n",
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.manifold import TSNE\n",
    "import keras\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "736983bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(108201, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Utterances</th>\n",
       "      <th>Basic</th>\n",
       "      <th>General</th>\n",
       "      <th>Full</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>fe016</td>\n",
       "      <td>so um</td>\n",
       "      <td>F</td>\n",
       "      <td>fh</td>\n",
       "      <td>fh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>fe016</td>\n",
       "      <td>i was going to try to get out of here like in ...</td>\n",
       "      <td>S</td>\n",
       "      <td>s</td>\n",
       "      <td>rt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>fe016</td>\n",
       "      <td>um</td>\n",
       "      <td>F</td>\n",
       "      <td>fh</td>\n",
       "      <td>fh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>fe016</td>\n",
       "      <td>because i really appreciate people coming.</td>\n",
       "      <td>S</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>fe016</td>\n",
       "      <td>and the main thing that i was going to ask peo...</td>\n",
       "      <td>S</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>fe016</td>\n",
       "      <td>so anything that transcribers or discourse cod...</td>\n",
       "      <td>S</td>\n",
       "      <td>s</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>fe016</td>\n",
       "      <td>so we have this um</td>\n",
       "      <td>D</td>\n",
       "      <td>fh</td>\n",
       "      <td>fh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>fe016</td>\n",
       "      <td>i think a starting point is clearly the the ch...</td>\n",
       "      <td>S</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>fe016</td>\n",
       "      <td>which don brought a copy of.</td>\n",
       "      <td>S</td>\n",
       "      <td>s</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>me011</td>\n",
       "      <td>yeah.</td>\n",
       "      <td>B</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 Speaker                                         Utterances  \\\n",
       "0           0   fe016                                              so um   \n",
       "1           1   fe016  i was going to try to get out of here like in ...   \n",
       "2           2   fe016                                                 um   \n",
       "3           3   fe016         because i really appreciate people coming.   \n",
       "4           4   fe016  and the main thing that i was going to ask peo...   \n",
       "5           5   fe016  so anything that transcribers or discourse cod...   \n",
       "6           6   fe016                                 so we have this um   \n",
       "7           7   fe016  i think a starting point is clearly the the ch...   \n",
       "8           8   fe016                       which don brought a copy of.   \n",
       "9           9   me011                                              yeah.   \n",
       "\n",
       "  Basic General Full  \n",
       "0     F      fh   fh  \n",
       "1     S       s   rt  \n",
       "2     F      fh   fh  \n",
       "3     S       s    s  \n",
       "4     S       s    s  \n",
       "5     S       s    e  \n",
       "6     D      fh   fh  \n",
       "7     S       s    s  \n",
       "8     S       s    e  \n",
       "9     B       b    b  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('C:\\\\Users\\\\user1\\\\Documents\\\\repo\\\\dialog act RNN\\\\MRDA\\\\full_set.csv')\n",
    "print(data.shape)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a27269f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Utterances</th>\n",
       "      <th>Basic</th>\n",
       "      <th>General</th>\n",
       "      <th>Full</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fe016</td>\n",
       "      <td>so um</td>\n",
       "      <td>F</td>\n",
       "      <td>fh</td>\n",
       "      <td>fh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fe016</td>\n",
       "      <td>i was going to try to get out of here like in ...</td>\n",
       "      <td>S</td>\n",
       "      <td>s</td>\n",
       "      <td>rt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fe016</td>\n",
       "      <td>um</td>\n",
       "      <td>F</td>\n",
       "      <td>fh</td>\n",
       "      <td>fh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fe016</td>\n",
       "      <td>because i really appreciate people coming.</td>\n",
       "      <td>S</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fe016</td>\n",
       "      <td>and the main thing that i was going to ask peo...</td>\n",
       "      <td>S</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Speaker                                         Utterances Basic General  \\\n",
       "0   fe016                                              so um     F      fh   \n",
       "1   fe016  i was going to try to get out of here like in ...     S       s   \n",
       "2   fe016                                                 um     F      fh   \n",
       "3   fe016         because i really appreciate people coming.     S       s   \n",
       "4   fe016  and the main thing that i was going to ask peo...     S       s   \n",
       "\n",
       "  Full  \n",
       "0   fh  \n",
       "1   rt  \n",
       "2   fh  \n",
       "3    s  \n",
       "4    s  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=data.drop(columns=[\"Unnamed: 0\"])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb044b83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                so um\n",
       "1    i was going to try to get out of here like in ...\n",
       "2                                                   um\n",
       "3            because i really appreciate people coming\n",
       "4    and the main thing that i was going to ask peo...\n",
       "Name: Utterances, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Utterances'] = data['Utterances'].apply(lambda x: x.lower())\n",
    "data['Utterances'] = data['Utterances'].apply(lambda x: re.sub('[^a-zA-z0-9\\s]','',x))\n",
    "data['Utterances'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5eaaeadd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Full\n",
       "%       3103\n",
       "2        841\n",
       "aa      5898\n",
       "aap      219\n",
       "am       349\n",
       "ar       908\n",
       "arp      150\n",
       "b      15013\n",
       "ba      2216\n",
       "bc        51\n",
       "bd       387\n",
       "bh       154\n",
       "bk      7177\n",
       "br       236\n",
       "bs       141\n",
       "bsc      150\n",
       "bu      2091\n",
       "by        11\n",
       "cc       371\n",
       "co       674\n",
       "cs      2662\n",
       "d       1805\n",
       "df      3724\n",
       "e       3200\n",
       "f        128\n",
       "fa       259\n",
       "fe       307\n",
       "fg      3091\n",
       "fh      8362\n",
       "ft       119\n",
       "fw         6\n",
       "g         87\n",
       "h        792\n",
       "j        463\n",
       "m        293\n",
       "na      1112\n",
       "nd       483\n",
       "ng       351\n",
       "no       828\n",
       "qh       214\n",
       "qo        74\n",
       "qr       127\n",
       "qrr      345\n",
       "qw       951\n",
       "qy       669\n",
       "r        208\n",
       "rt      3101\n",
       "s      33472\n",
       "t        253\n",
       "t1       198\n",
       "t3       165\n",
       "tc       212\n",
       "Name: Full, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print((data.groupby('Full')['Full'].agg('count')).size)\n",
    "data.groupby('Full')['Full'].agg('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22966f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fh [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "rt [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "fh [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "s [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "s [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.get_dummies(data['Full']).values\n",
    "[print(data['Full'][i],y[i]) for i in range (0,5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7fad851",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['Utterances']\n",
    "tokenizer = Tokenizer(num_words = 4000)\n",
    "tokenizer.fit_on_texts(X)\n",
    "sequence = tokenizer.texts_to_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "550c7eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11113\n"
     ]
    }
   ],
   "source": [
    "index_of_words = tokenizer.word_index\n",
    "print(len(index_of_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9760e24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11, 16,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pad_sequences(sequence , maxlen = 77 , padding='post')\n",
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e97c9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "f = open(\"C:\\\\Users\\\\user1\\\\Downloads\\\\glove.6B\\\\glove.6B.300d.txt\",  encoding=\"utf8\")\n",
    "embedd_index = {}\n",
    "for line in f:\n",
    "    val = line.split()\n",
    "    word = val[0]\n",
    "    coff = np.asarray(val[1:],dtype = 'float')\n",
    "    embedd_index[word] = coff\n",
    "\n",
    "f.close()\n",
    "print('Found %s word vectors.' % len(embedd_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b658087b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.3602e-01, -1.1594e-01, -1.7078e-02, -2.9256e-01,  1.6149e-02,\n",
       "        8.6472e-02,  1.5759e-03,  3.4395e-01,  2.1661e-01, -2.1366e+00,\n",
       "        3.5278e-01, -2.3909e-01, -2.2174e-01,  3.6413e-01, -4.5021e-01,\n",
       "        1.2104e-01, -1.5596e-01, -3.8906e-02, -2.9419e-03,  1.6009e-02,\n",
       "       -1.1620e-01,  3.8680e-01,  3.5109e-01,  9.7426e-02, -1.2425e-02,\n",
       "       -1.7864e-01, -2.3259e-01, -2.6960e-01,  4.1083e-02, -7.6194e-02,\n",
       "       -2.3362e-01,  2.0919e-01, -2.7264e-01,  5.4967e-02, -1.8055e+00,\n",
       "        5.6348e-01, -1.2778e-01,  2.3147e-01, -5.8820e-03, -2.6630e-01,\n",
       "        4.1187e-01, -3.7162e-01, -2.0600e-01, -1.9619e-01, -4.3945e-03,\n",
       "        1.2513e-01,  4.6638e-01,  4.5159e-01, -1.5000e-01,  5.9589e-03,\n",
       "        5.9070e-02, -4.1440e-01,  6.1035e-02, -2.1117e-01, -4.0988e-01,\n",
       "        5.6393e-01,  2.3021e-01,  2.7240e-01,  4.9364e-02,  1.4239e-01,\n",
       "        4.1841e-01, -1.3983e-01,  3.4826e-01, -1.0745e-01, -2.5002e-01,\n",
       "       -3.2554e-01,  3.3343e-01, -3.5617e-01,  2.0442e-01,  1.4439e-01,\n",
       "       -1.2686e-01, -7.7273e-02, -1.9667e-01,  1.0759e-01, -1.1860e-01,\n",
       "       -2.5083e-01,  1.4205e-02,  2.7251e-01, -2.3707e-01, -2.3545e-01,\n",
       "       -1.5887e-01,  1.3151e-01,  6.9564e-01,  2.2766e-01,  1.8526e-01,\n",
       "        1.5743e-01, -1.5018e-01, -1.8177e-01, -3.3527e-02, -3.3092e-01,\n",
       "       -2.5205e-01,  5.0913e-01, -2.5607e-01, -5.3686e-01,  1.3397e-01,\n",
       "        6.7046e-02, -9.4473e-02, -2.2270e-01, -3.1469e-01,  8.5932e-02,\n",
       "       -4.3032e-02, -2.5821e-01, -9.5062e-02, -1.8497e-01,  5.8890e-02,\n",
       "        1.8972e-01, -1.7366e-01,  2.5263e-01, -5.4361e-01, -3.7248e-01,\n",
       "       -4.6661e-02, -4.1657e-01, -1.7549e-03, -4.8404e-01,  4.2090e-01,\n",
       "       -1.2749e-03,  9.4697e-03, -1.3380e-01,  7.2351e-02, -1.2096e-01,\n",
       "       -7.2870e-02, -1.8333e-01,  3.9652e-01,  1.1329e-01, -6.3029e-02,\n",
       "       -1.9702e-03,  4.2848e-01,  3.1790e-01, -1.5079e-01,  2.0405e-01,\n",
       "        2.1828e-01,  2.6067e-02,  4.3621e-02,  3.9224e-03, -2.6629e-01,\n",
       "       -2.8312e-01,  5.0497e-02, -1.8993e-01,  1.8996e-01,  2.9517e-01,\n",
       "       -1.1566e-01,  4.0967e-01,  2.2221e-01, -3.9778e-01, -3.3177e-01,\n",
       "       -1.3884e-01, -1.6829e-01, -2.0355e-01, -2.7687e-01, -1.1087e-01,\n",
       "       -6.7466e-01, -1.8108e-01,  1.8512e-01, -9.4616e-02,  1.7856e-01,\n",
       "       -6.6997e-02,  1.1379e-01, -9.3380e-02,  5.6860e-01, -1.3365e-01,\n",
       "        3.4636e-01, -4.1953e-01,  1.7547e-01, -2.4277e-02, -1.2441e-01,\n",
       "        9.2129e-02, -1.6702e-01, -1.4285e-01,  3.1646e-01,  3.0337e-01,\n",
       "        1.4840e-01, -6.7837e-03, -1.0509e+00,  2.2329e-01,  7.5211e-02,\n",
       "        4.4379e-02, -8.5929e-02, -1.1806e-01, -1.6632e-01, -7.8650e-02,\n",
       "        2.6374e-01, -2.2052e-01,  4.5582e-01, -1.5291e-01,  6.2617e-02,\n",
       "       -1.5588e-01,  8.2398e-02, -6.8462e-02, -2.4569e-01,  2.3439e-01,\n",
       "       -3.8633e-01,  2.4835e-01,  2.5334e-01, -2.1189e-01,  4.1494e-03,\n",
       "       -4.3762e-01, -1.3426e-01, -2.4583e-01,  1.4213e-01, -3.3973e-01,\n",
       "        1.4643e+00,  1.6414e-01,  2.2135e-01,  7.4099e-03, -5.5141e-02,\n",
       "       -2.7403e-02,  3.2928e-02,  1.4289e-01, -1.0049e-01, -2.2066e-01,\n",
       "       -3.0380e-01,  6.0624e-02, -1.2408e-01, -5.4114e-01,  2.4374e-01,\n",
       "        8.0903e-02, -7.8264e-02,  8.0091e-02,  9.8551e-03, -2.3077e-01,\n",
       "        1.6006e-01,  6.4075e-02, -4.1613e-01,  2.0494e-01, -1.8681e-01,\n",
       "        3.5367e-02,  2.1759e-01, -8.7823e-02,  3.5452e-01,  1.9578e-01,\n",
       "       -1.5127e-01, -1.0545e-01,  3.5650e-01, -3.8677e-01, -6.3172e-02,\n",
       "        3.1534e-01, -1.5887e-01, -3.1267e-01, -1.7893e-01,  4.1952e-01,\n",
       "        2.3261e-01,  2.0943e-01,  2.7013e-02,  1.7388e-02, -5.9857e-01,\n",
       "       -1.9622e-01, -2.3672e-01,  3.0032e-01,  4.6926e-02, -8.5768e-02,\n",
       "        3.6539e-01, -5.2476e-01, -1.3618e-01,  1.0868e-01,  4.6307e-01,\n",
       "        3.8502e-01,  7.6317e-04, -3.8196e-01,  7.9772e-02, -4.1744e-02,\n",
       "        4.7625e-02, -4.1018e-02,  1.7601e-01,  2.4893e-01, -1.0753e-01,\n",
       "        3.1935e-01, -1.2762e-01, -3.5059e-01,  3.5689e-04,  9.3515e-03,\n",
       "       -8.8616e-02, -3.2785e-01,  9.2063e-02, -6.1405e-02,  2.9053e-01,\n",
       "        2.2404e-02, -1.6879e+00,  2.6712e-01,  3.3419e-01, -5.2533e-02,\n",
       "       -1.9741e-01,  1.3709e-01, -5.4288e-02,  5.6423e-01,  1.9384e-01,\n",
       "        1.7229e-01,  2.9025e-01, -1.6124e-01,  5.9489e-02, -3.1884e-01,\n",
       "       -2.8343e-01,  6.4321e-02, -4.1589e-01, -7.0528e-02,  1.2410e-02,\n",
       "       -4.0208e-01, -2.4963e-01, -3.3760e-01,  7.0098e-02,  2.4642e-01])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedd_index['good']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0bc2bcbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11114, 300)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((len(index_of_words) + 1, 300))\n",
    "\n",
    "tokens = []\n",
    "labels = []\n",
    "\n",
    "for word,i in index_of_words.items():\n",
    "    temp = embedd_index.get(word)\n",
    "    if temp is not None:\n",
    "        embedding_matrix[i] = temp\n",
    "        \n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9468c479",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedd_layer = Embedding(len(index_of_words) + 1 , 300 , input_length = 77 , weights = [embedding_matrix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "009ce866",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 77)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 77, 300)      3334200     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 256)          439296      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            257         bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 1)            0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector (RepeatVector)    (None, 256, 1)       0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "permute (Permute)               (None, 1, 256)       0           repeat_vector[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 1, 256)       0           bidirectional[0][0]              \n",
      "                                                                 permute[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 256)          0           multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 52)           13364       lambda[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 3,787,117\n",
      "Trainable params: 3,787,117\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "MAX_LENGTH_PER_SENTENCE=77\n",
    "units = 128\n",
    "encoder_input = keras.Input(shape=(MAX_LENGTH_PER_SENTENCE))\n",
    "x = layers.Embedding(len(index_of_words) + 1 , 300 , input_length = 77 , weights = [embedding_matrix])(encoder_input)\n",
    "                              \n",
    "activations = layers.Bidirectional(layers.LSTM(units, dropout=0.3, recurrent_dropout=0.2))(x)\n",
    "\n",
    "attention = layers.Dense(1, activation='tanh')(activations)\n",
    "attention = layers.Flatten()(attention)\n",
    "attention = layers.Activation('softmax')(attention)\n",
    "attention = layers.RepeatVector(units*2)(attention)\n",
    "attention = layers.Permute((2, 1))(attention)\n",
    "\n",
    "sent_representation = layers.Multiply()([activations, attention])\n",
    "sent_representation = layers.Lambda(lambda X: K.sum(X, axis=-2), output_shape=(units*2,))(sent_representation)\n",
    "\n",
    "\n",
    "probabilities = layers.Dense(52, activation='softmax')(sent_representation)\n",
    "\n",
    "\n",
    "encoder = keras.Model(inputs=[encoder_input], outputs=[probabilities],name='encoder')\n",
    "\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "999a8aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4376b8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b66999a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "2705/2705 [==============================] - 1045s 385ms/step - loss: 1.5993 - accuracy: 0.5662\n",
      "Epoch 2/3\n",
      "2705/2705 [==============================] - 1024s 378ms/step - loss: 1.4085 - accuracy: 0.5933\n",
      "Epoch 3/3\n",
      "2705/2705 [==============================] - 955s 353ms/step - loss: 1.3400 - accuracy: 0.6035\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23a3366f310>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.fit(X_train, y_train, epochs=3, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4722fb5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "677/677 [==============================] - 26s 39ms/step - loss: 1.4116 - accuracy: 0.5859\n"
     ]
    }
   ],
   "source": [
    "score = encoder.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5279c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 15   1 517   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(X_test[1])\n",
    "print(y_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "acfd1f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of example  (1, 77)\n",
      "Shape of predicted  (1, 52)\n",
      "Prediction [[6.49838969e-02 2.89740320e-03 6.86646765e-03 3.20238504e-03\n",
      "  3.18196253e-03 4.41392505e-04 4.43256984e-04 2.41305475e-04\n",
      "  1.54551817e-03 5.53842809e-04 2.98100105e-03 5.05947741e-04\n",
      "  4.35007922e-03 7.80498842e-03 1.03675376e-03 1.82005402e-03\n",
      "  5.36284503e-03 6.58679754e-04 2.84166588e-03 3.74936988e-03\n",
      "  6.68847933e-03 4.21740580e-03 1.06671415e-02 1.53272916e-02\n",
      "  1.68353887e-04 2.88603973e-04 1.31032197e-03 2.66406173e-03\n",
      "  1.32943632e-03 1.06409374e-04 2.86152881e-05 1.77746944e-04\n",
      "  6.39094680e-04 2.36546732e-02 2.97787553e-03 7.31115937e-02\n",
      "  8.22441652e-03 2.22205860e-03 2.50555365e-03 2.05044798e-03\n",
      "  3.64894659e-04 1.74723769e-04 1.32400062e-04 2.68715434e-03\n",
      "  4.51110443e-03 8.39057285e-03 2.04737354e-02 6.49385333e-01\n",
      "  1.20557677e-02 9.44228936e-03 1.14397816e-02 7.11387303e-03]]\n",
      "Max value 0.64938533\n",
      "Index of the max value  [47]\n"
     ]
    }
   ],
   "source": [
    "a = [\"My name is rahul\"]\n",
    "a = tokenizer.texts_to_sequences(a)\n",
    "a = np.array(a)\n",
    "a = pad_sequences(a, padding='post', maxlen=77)\n",
    "prediction = encoder.predict(np.array(a))\n",
    "print(\"Shape of example \", a.shape)\n",
    "print(\"Shape of predicted \", prediction.shape)\n",
    "print(\"Prediction\", prediction)\n",
    "print(\"Max value\", np.max(prediction))\n",
    "print(\"Index of the max value \" , prediction.argmax(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e67110",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
