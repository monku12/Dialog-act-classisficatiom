{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "732fc929",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, LSTM, Embedding, Dropout, Bidirectional, Permute, Flatten, Activation, RepeatVector, Permute, Multiply, Lambda\n",
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c03f5d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(108201, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Utterances</th>\n",
       "      <th>Basic</th>\n",
       "      <th>General</th>\n",
       "      <th>Full</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>fe016</td>\n",
       "      <td>so um</td>\n",
       "      <td>F</td>\n",
       "      <td>fh</td>\n",
       "      <td>fh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>fe016</td>\n",
       "      <td>i was going to try to get out of here like in ...</td>\n",
       "      <td>S</td>\n",
       "      <td>s</td>\n",
       "      <td>rt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>fe016</td>\n",
       "      <td>um</td>\n",
       "      <td>F</td>\n",
       "      <td>fh</td>\n",
       "      <td>fh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>fe016</td>\n",
       "      <td>because i really appreciate people coming.</td>\n",
       "      <td>S</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>fe016</td>\n",
       "      <td>and the main thing that i was going to ask peo...</td>\n",
       "      <td>S</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>fe016</td>\n",
       "      <td>so anything that transcribers or discourse cod...</td>\n",
       "      <td>S</td>\n",
       "      <td>s</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>fe016</td>\n",
       "      <td>so we have this um</td>\n",
       "      <td>D</td>\n",
       "      <td>fh</td>\n",
       "      <td>fh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>fe016</td>\n",
       "      <td>i think a starting point is clearly the the ch...</td>\n",
       "      <td>S</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>fe016</td>\n",
       "      <td>which don brought a copy of.</td>\n",
       "      <td>S</td>\n",
       "      <td>s</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>me011</td>\n",
       "      <td>yeah.</td>\n",
       "      <td>B</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 Speaker                                         Utterances  \\\n",
       "0           0   fe016                                              so um   \n",
       "1           1   fe016  i was going to try to get out of here like in ...   \n",
       "2           2   fe016                                                 um   \n",
       "3           3   fe016         because i really appreciate people coming.   \n",
       "4           4   fe016  and the main thing that i was going to ask peo...   \n",
       "5           5   fe016  so anything that transcribers or discourse cod...   \n",
       "6           6   fe016                                 so we have this um   \n",
       "7           7   fe016  i think a starting point is clearly the the ch...   \n",
       "8           8   fe016                       which don brought a copy of.   \n",
       "9           9   me011                                              yeah.   \n",
       "\n",
       "  Basic General Full  \n",
       "0     F      fh   fh  \n",
       "1     S       s   rt  \n",
       "2     F      fh   fh  \n",
       "3     S       s    s  \n",
       "4     S       s    s  \n",
       "5     S       s    e  \n",
       "6     D      fh   fh  \n",
       "7     S       s    s  \n",
       "8     S       s    e  \n",
       "9     B       b    b  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('C:\\\\Users\\\\user1\\\\Documents\\\\repo\\\\dialog act RNN\\\\MRDA\\\\full_set.csv')\n",
    "print(data.shape)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfebf209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Utterances</th>\n",
       "      <th>Basic</th>\n",
       "      <th>General</th>\n",
       "      <th>Full</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fe016</td>\n",
       "      <td>so um</td>\n",
       "      <td>F</td>\n",
       "      <td>fh</td>\n",
       "      <td>fh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fe016</td>\n",
       "      <td>i was going to try to get out of here like in ...</td>\n",
       "      <td>S</td>\n",
       "      <td>s</td>\n",
       "      <td>rt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fe016</td>\n",
       "      <td>um</td>\n",
       "      <td>F</td>\n",
       "      <td>fh</td>\n",
       "      <td>fh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fe016</td>\n",
       "      <td>because i really appreciate people coming.</td>\n",
       "      <td>S</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fe016</td>\n",
       "      <td>and the main thing that i was going to ask peo...</td>\n",
       "      <td>S</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Speaker                                         Utterances Basic General  \\\n",
       "0   fe016                                              so um     F      fh   \n",
       "1   fe016  i was going to try to get out of here like in ...     S       s   \n",
       "2   fe016                                                 um     F      fh   \n",
       "3   fe016         because i really appreciate people coming.     S       s   \n",
       "4   fe016  and the main thing that i was going to ask peo...     S       s   \n",
       "\n",
       "  Full  \n",
       "0   fh  \n",
       "1   rt  \n",
       "2   fh  \n",
       "3    s  \n",
       "4    s  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=data.drop(columns=[\"Unnamed: 0\"])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c459dff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                so um\n",
       "1    i was going to try to get out of here like in ...\n",
       "2                                                   um\n",
       "3            because i really appreciate people coming\n",
       "4    and the main thing that i was going to ask peo...\n",
       "Name: Utterances, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Utterances'] = data['Utterances'].apply(lambda x: x.lower())\n",
    "data['Utterances'] = data['Utterances'].apply(lambda x: re.sub('[^a-zA-z0-9\\s]','',x))\n",
    "data['Utterances'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d683ecb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Full\n",
       "%       3103\n",
       "2        841\n",
       "aa      5898\n",
       "aap      219\n",
       "am       349\n",
       "ar       908\n",
       "arp      150\n",
       "b      15013\n",
       "ba      2216\n",
       "bc        51\n",
       "bd       387\n",
       "bh       154\n",
       "bk      7177\n",
       "br       236\n",
       "bs       141\n",
       "bsc      150\n",
       "bu      2091\n",
       "by        11\n",
       "cc       371\n",
       "co       674\n",
       "cs      2662\n",
       "d       1805\n",
       "df      3724\n",
       "e       3200\n",
       "f        128\n",
       "fa       259\n",
       "fe       307\n",
       "fg      3091\n",
       "fh      8362\n",
       "ft       119\n",
       "fw         6\n",
       "g         87\n",
       "h        792\n",
       "j        463\n",
       "m        293\n",
       "na      1112\n",
       "nd       483\n",
       "ng       351\n",
       "no       828\n",
       "qh       214\n",
       "qo        74\n",
       "qr       127\n",
       "qrr      345\n",
       "qw       951\n",
       "qy       669\n",
       "r        208\n",
       "rt      3101\n",
       "s      33472\n",
       "t        253\n",
       "t1       198\n",
       "t3       165\n",
       "tc       212\n",
       "Name: Full, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print((data.groupby('Full')['Full'].agg('count')).size)\n",
    "data.groupby('Full')['Full'].agg('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80f942a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(108201, 77)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  11,   16,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   2,   36,   59,    4,  168,    4,   61,   81,   10,   97,   35,\n",
       "          15,  438,   86,  659,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [  16,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [  50,    2,   69, 1944,   84,  410,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   3,    1,  664,   62,    5,    2,   36,   59,    4,  246,   84,\n",
       "           4,  325,   37,  518,   13,    4,  214,  593,   32,   27,  433,\n",
       "          10,  691,  515,   14,   96,  107,   15,  574,    4,  977,   79,\n",
       "          68,   35,  224,  481,    3, 2013,   10,  224,  481,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words = 5000, split=\" \")\n",
    "tokenizer.fit_on_texts(data['Utterances'].values)\n",
    "X = tokenizer.texts_to_sequences(data['Utterances'].values)\n",
    "X = pad_sequences(X, padding='post')\n",
    "print(X.shape)\n",
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2f0881e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH_PER_SENTENCE=77\n",
    "units = 128\n",
    "encoder_input = keras.Input(shape=(MAX_LENGTH_PER_SENTENCE))\n",
    "x =layers.Embedding(input_dim=5000, output_dim=256, input_length=X.shape[1])(encoder_input)\n",
    "                              \n",
    "activations = Bidirectional(tf.keras.layers.LSTM(units, dropout=0.3, recurrent_dropout=0.2))(x)\n",
    "\n",
    "attention = Dense(1, activation='tanh')(activations)\n",
    "attention = Flatten()(attention)\n",
    "attention = Activation('softmax')(attention)\n",
    "attention = RepeatVector(units*2)(attention)\n",
    "attention = Permute((2, 1))(attention)\n",
    "\n",
    "sent_representation = Multiply()([activations, attention])\n",
    "sent_representation = Lambda(lambda xin: K.sum(xin, axis=-2), output_shape=(units*2,))(sent_representation)\n",
    "\n",
    "\n",
    "probabilities = Dense(52, activation='softmax')(sent_representation)\n",
    "\n",
    "\n",
    "encoder = keras.Model(inputs=[encoder_input], outputs=[probabilities],name='encoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2454c14a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 77)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 77, 256)      1280000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 256)          394240      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            257         bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 1)            0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector (RepeatVector)    (None, 256, 1)       0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "permute (Permute)               (None, 1, 256)       0           repeat_vector[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 1, 256)       0           bidirectional[0][0]              \n",
      "                                                                 permute[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 256)          0           multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 52)           13364       lambda[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 1,687,861\n",
      "Trainable params: 1,687,861\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5359c63f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fh [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "rt [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "fh [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "s [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "s [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.get_dummies(data['Full']).values\n",
    "[print(data['Full'][i],y[i]) for i in range (0,5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66a1cf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3d039c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "2705/2705 [==============================] - 1987s 733ms/step - loss: 1.6499 - accuracy: 0.5610\n",
      "Epoch 2/3\n",
      "2705/2705 [==============================] - 2090s 773ms/step - loss: 1.4185 - accuracy: 0.5923\n",
      "Epoch 3/3\n",
      "2705/2705 [==============================] - 1513s 559ms/step - loss: 1.3409 - accuracy: 0.6051\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ddb52afeb0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.fit(X_train, y_train, epochs=3, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a08447e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "677/677 [==============================] - 54s 76ms/step - loss: 1.4302 - accuracy: 0.5930\n"
     ]
    }
   ],
   "source": [
    "score = encoder.evaluate(X_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ac6821e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 59.30410027503967\n",
      "[ 15   1 517   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", score[1]*100)\n",
    "print(X_test[1])\n",
    "print(y_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40ce4390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of example  (1, 77)\n",
      "Shape of predicted  (1, 52)\n",
      "Prediction [[2.8074702e-02 5.8301650e-03 5.0202999e-03 3.9070328e-03 2.5314579e-03\n",
      "  6.2030926e-04 5.3803663e-04 8.0874533e-04 3.8110144e-03 5.9513492e-04\n",
      "  2.5198697e-03 3.0175794e-04 4.9915956e-03 3.4932401e-03 7.2252436e-04\n",
      "  2.0353943e-03 7.1896911e-03 2.7220356e-04 5.0850320e-03 5.1762760e-03\n",
      "  1.1268931e-02 4.2823548e-03 7.5719547e-03 7.7434797e-03 8.0090758e-05\n",
      "  1.9554584e-04 6.8884547e-04 6.0430951e-03 1.3054860e-03 1.7386785e-04\n",
      "  4.2062500e-05 2.9607411e-04 4.3036358e-04 1.4738229e-02 2.7782931e-03\n",
      "  3.3114899e-02 4.1778577e-03 6.2481915e-03 1.3458595e-03 2.0051193e-03\n",
      "  4.5698383e-04 2.0340513e-04 4.8366386e-05 3.2992042e-03 4.6516233e-03\n",
      "  9.5870728e-03 3.4225080e-02 7.2584814e-01 9.4675757e-03 5.3551826e-03\n",
      "  1.0572188e-02 8.2300566e-03]]\n",
      "Max value 0.72584814\n",
      "Index of the max value  [47]\n"
     ]
    }
   ],
   "source": [
    "a = [\"My name is rahul\"]\n",
    "a = tokenizer.texts_to_sequences(a)\n",
    "a = np.array(a)\n",
    "a = pad_sequences(a, padding='post', maxlen=77)\n",
    "prediction = encoder.predict(np.array(a))\n",
    "print(\"Shape of example \", a.shape)\n",
    "print(\"Shape of predicted \", prediction.shape)\n",
    "print(\"Prediction\", prediction)\n",
    "print(\"Max value\", np.max(prediction))\n",
    "print(\"Index of the max value \" , prediction.argmax(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a8d910",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
